@ARTICLE{Samuel, 
author={A. L. {Samuel}}, 
journal={IBM Journal of Research and Development}, 
title={Some studies in machine learning using the game of checkers}, 
year={2000}, 
volume={44}, 
number={1.2}, 
pages={206-226}, 
keywords={}, 
doi={10.1147/rd.441.0206}, 
ISSN={0018-8646}, 
month={Jan},}

@ARTICLE{Intriguing,
author = {{Szegedy}, Christian and {Zaremba}, Wojciech and {Sutskever}, Ilya and
 {Bruna}, Joan and {Erhan}, Dumitru and {Goodfellow}, Ian and
 {Fergus}, Rob},
title = "{Intriguing properties of neural networks}",
journal = {arXiv e-prints},
keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
 year = "2013",
month = "Dec",
eid = {arXiv:1312.6199},
pages = {arXiv:1312.6199},
archivePrefix = {arXiv},
eprint = {1312.6199},
primaryClass = {cs.CV},
adsurl = {https://ui.adsabs.harvard.edu/\#abs/2013arXiv1312.6199S},
adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{mcculloch, 
author={McCulloch, Warren S. and Pitts, Walter}, 
title={A logical calculus of the ideas immanent in nervous activity}, 
year={1943},
adsurl={https://link.springer.com/article/10.1007/BF02478259}, journal={SpringerLink}, publisher={springer}
}

@inbook{neuron,
author = {Dash, Nilamadhab and Priyadarshini, Rojalina and Mishra, Brojo and Misra, Rachita},
year = {2017},
month = {01},
pages = {246-274},
title = {Bio-Inspired Computing through Artificial Neural Network},
doi = {10.4018/978-1-5225-1008-6.ch011},
adsurl={https://www.researchgate.net/publication/312946913_Bio-Inspired_Computing_through_Artificial_Neural_Network}
}

@article{multi,
title = "Approximation capabilities of multilayer feedforward networks",
journal = "Neural Networks",
volume = "4",
number = "2",
pages = "251 - 257",
year = "1991",
issn = "0893-6080",
doi = "https://doi.org/10.1016/0893-6080(91)90009-T",
url = "http://www.sciencedirect.com/science/article/pii/089360809190009T",
author = "Kurt Hornik",
keywords = "Multilayer feedforward networks, Activation function, Universal approximation capabilities, Input environment measure, () approximation, Uniform approximation, Sobolev spaces, Smooth approximation",
abstract = "We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(μ) performance criteria, for arbitrary finite input environment measures μ, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives."
}

@article{survey,
title = "Adversarial Attacks and Defenses Against Deep Neural Networks: A Survey",
journal = "Procedia Computer Science",
volume = "140",
pages = "152 - 161",
year = "2018",
note = "Cyber Physical Systems and Deep Learning Chicago, Illinois November 5-7, 2018",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2018.10.315",
url = "http://www.sciencedirect.com/science/article/pii/S1877050918319884",
author = "Mesut Ozdag",
keywords = "deep learning, deep neural network, adversarial examples, security",
abstract = "Deep learning has achieved great successes in various types of applications over recent years. On the other hand, it has been found that deep neural networks (DNNs) can be easily fooled by adversarial input samples. This vulnerability raises major concerns in security-sensitive environments. Therefore, research in attacking and defending DNNs with adversarial examples has drawn great attention. The goal of this paper is to review the types of adversarial attacks and defenses, describe the state-of-the-art methods for each group, and compare their results. In addition, we present some of the top-scored competition submissions for Neural Information Processing Systems (NIPS) in 2017, their solution models, and demonstrate their results. This adversary competition was organized by Google Brain for research scientists to come up with novel solutions that generate adversarial examples and also defend against them. Its contribution is significant on this era of machine learning and DNNs."
}

@INPROCEEDINGS{CNN,
    author = {Yann Lecun and Léon Bottou and Yoshua Bengio and Patrick Haffner},
    title = {Gradient-based learning applied to document recognition},
    booktitle = {Proceedings of the IEEE},
    year = {1998},
    pages = {2278--2324}
}

