% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 1. \emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Overview}

Sixty years ago, Arthur Samuel published a paper about two machine learning procedures using the game of draughts thus laying the foundation of this area  \cite{Samuel}. Machine learning is not a new topic,  but the number of applications using it is increasing exponentially with the development of deep learning techniques. This was made possible by the capacity to recover and store more data than before and the constant improvement of the computer performances. Moreover, deep learning is based on the training of artificial networks and these networks have now acquired enough maturity to be used in the resolution of real-world problems compared to more traditional data-analysis methods. 
Face detection and recognition, traffic sign recognition and handwriting recognition are some examples of these real-world problems deep learning can answer. 




%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Motivations and objectives}


It is possible to change the network's prediction by applying imperceptible perturbation to an image \cite{Intriguing}. A human would not see any differences between the original image and the modified one. These examples are known as adversarial examples. As the tasks given to these networks could be of major importance, the existence of these adversarial examples questions about the safe use of neural networks as secure systems could be compromised. 
Respecting this concern, the problem area this project addresses is the robustness of artificial neural networks, in other words,  its ability to make the correct prediction despite perturbations. As it is important to be able to evaluate the robustness of a neural network, some tools have been developed to verify their safety. The goal of this project is to investigate on one of these tools called DLV which is an automated verification framework for feed-forward multi-layer neural networks.
This involves a good understanding of the theory behind this tool to figure out how the modification of its configuration affects its outputs.


\section{Structure of this paper}
